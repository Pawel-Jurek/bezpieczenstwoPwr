import{_ as a,c as s,o as i,ae as t}from"./chunks/framework.Dh1jimFm.js";const g=JSON.parse('{"title":"📊 Data & Models","description":"","frontmatter":{},"headers":[],"relativePath":"src/data-and-models.md","filePath":"src/data-and-models.md"}'),n={name:"src/data-and-models.md"};function o(r,e,l,d,p,h){return i(),s("div",null,e[0]||(e[0]=[t(`<h1 id="📊-data-models" tabindex="-1">📊 Data &amp; Models <a class="header-anchor" href="#📊-data-models" aria-label="Permalink to &quot;📊 Data &amp; Models&quot;">​</a></h1><p>This section covers how behavioral data is used to train machine learning models in <strong>bezpieczenstwoPwr</strong>, as well as how those models are integrated and run in the browser.</p><h2 id="📁-data-source" tabindex="-1">📁 Data Source <a class="header-anchor" href="#📁-data-source" aria-label="Permalink to &quot;📁 Data Source&quot;">​</a></h2><p>The machine learning models are trained using anonymized user behavior data, primarily from:</p><ul><li><a href="https://www.kaggle.com/" target="_blank" rel="noreferrer">Kaggle datasets</a> related to <strong>mouse movement</strong>, <strong>bot detection</strong>, or <strong>human-computer interaction</strong></li><li>Custom-collected data from real users and simulation tools (e.g., puppeteer)</li></ul><p>Typical features include:</p><ul><li>Mouse speed and acceleration</li><li>Click patterns and hesitation times</li><li>Pointer trajectory shapes</li><li>Keystroke intervals and input dynamics</li></ul><blockquote><p>🧠 All data is anonymized before any storage or model training. No personally identifiable information is collected.</p></blockquote><h2 id="🛠-data-preprocessing" tabindex="-1">🛠 Data Preprocessing <a class="header-anchor" href="#🛠-data-preprocessing" aria-label="Permalink to &quot;🛠 Data Preprocessing&quot;">​</a></h2><p>Before feeding data into the model, we perform several preprocessing steps:</p><ul><li><strong>Normalization</strong> of coordinates and timing</li><li><strong>Sequence padding</strong> or trimming to ensure consistent input shape</li><li><strong>Feature extraction</strong> such as velocity, direction changes, or dwell time</li><li><strong>Noise filtering</strong> to remove accidental or edge-case inputs</li></ul><p>You can find preprocessing code inside the training pipeline scripts (not yet published, ask us if you want early access).</p><h2 id="🧠-model-architecture" tabindex="-1">🧠 Model Architecture <a class="header-anchor" href="#🧠-model-architecture" aria-label="Permalink to &quot;🧠 Model Architecture&quot;">​</a></h2><p>Models are designed for lightweight, in-browser inference using <a href="https://www.tensorflow.org/js/" target="_blank" rel="noreferrer">TensorFlow.js</a>.</p><p>We experimented with:</p><ul><li>LSTM / GRU networks for time-sequence analysis</li><li>1D CNNs for spatial-temporal patterns</li><li>Ensemble methods trained offline and distilled into TensorFlow.js format</li></ul><p>The final model is selected based on size, accuracy, and inference speed in the browser.</p><blockquote><p>⚠️ Models are kept under <code>public/models/</code> for now. Expect a proper versioning system and CDN-hosted models in future updates.</p></blockquote><h2 id="📦-loading-models" tabindex="-1">📦 Loading Models <a class="header-anchor" href="#📦-loading-models" aria-label="Permalink to &quot;📦 Loading Models&quot;">​</a></h2><p>The <code>bbotd</code> package automatically loads a model from a given URL:</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bbotd.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">loadModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://yourdomain.com/models/1/model.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">then</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">((</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> prediction</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">predict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(userData);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">});</span></span></code></pre></div>`,21)]))}const u=a(n,[["render",o]]);export{g as __pageData,u as default};
